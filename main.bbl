% $ biblatex auxiliary file $
% $ biblatex bbl format version 2.9 $
% Do not modify the above lines!
%
% This is an auxiliary file used by the 'biblatex' package.
% This file may safely be deleted. It will be recreated as
% required.
%
\begingroup
\makeatletter
\@ifundefined{ver@biblatex.sty}
  {\@latex@error
     {Missing 'biblatex' package}
     {The bibliography requires the 'biblatex' package.}
      \aftergroup\endinput}
  {}
\endgroup

\datalist[entry]{nty/global//global/global}
  \entry{lpccvsmfcc}{article}{}
    \name{author}{1}{}{%
      {{hash=BU}{%
         family={Bhattacharjee},
         familyi={B\bibinitperiod},
         given={Utpal},
         giveni={U\bibinitperiod},
      }}%
    }
    \keyw{jit,training,vendor relationship}
    \strng{namehash}{BU1}
    \strng{fullhash}{BU1}
    \field{labelnamesource}{author}
    \field{labeltitlesource}{title}
    \field{sortinit}{B}
    \field{sortinithash}{B}
    \field{abstract}{%
    In this paper two popular feature extraction techniques Linear Predictive
  Cepstral Coefficients (LPCC) and Mel Frequency Cepstral Coefficients (MFCC)
  have been investigated and their performances have been evaluated for the
  recognition of Assamese phonemes. A multilayer perceptron based baseline
  phoneme recognizer has been built and all the experiments have been carried
  out using that recognizer. In the present study, attempt has been made to
  evaluate the performance of the speech recognition system with different
  feature set in quiet environmental condition as well as at different level of
  noise. It has been observed that at noise free operating environment when
  same speaker is used for training and testing the system, the system given
  100{\%} recognition accuracy for the recognition of Assamese phones for both
  the feature set. However, the performance of the system degrades considerably
  with increase in environmental noise level.It has been observed that the
  performance of LPCC based system degrades more rapidly compare to MFCC based
  system under environmental noise condition whereas under speaker variability
  conditions, LPCC shows relative robustness compare to MFCC though the
  performance of both the systems degrades considerably.%
    }
    \verb{doi}
    \verb 10.4236/jis.2012.34041
    \endverb
    \field{issn}{2153-1234}
    \field{number}{3}
    \field{pages}{1\bibrangedash 6}
    \field{title}{{A comparative study of LPCC and MFCC features for the
  recognition of Assamese phonemes}}
    \verb{url}
    \verb https://pdfs.semanticscholar.org/7c8f/8a9d5ba85788b569bc04ca9f07d6ce6
    \verb 89e8c.pdf
    \endverb
    \field{volume}{2}
    \verb{file}
    \verb :Users/joshfenech/Documents/Linux Documents Backup May/Documents/Shar
    \verb ed Documents/MLDM/Project/Papers/mfccvslpcc.pdf:pdf
    \endverb
    \field{journaltitle}{International Journal of Engineering Research {\&}
  Technology}
    \field{year}{2013}
  \endentry

  \entry{Campbell1996}{article}{}
    \name{author}{1}{}{%
      {{hash=CN}{%
         family={Campbell},
         familyi={C\bibinitperiod},
         given={N},
         giveni={N},
      }}%
    }
    \strng{namehash}{CN1}
    \strng{fullhash}{CN1}
    \field{labelnamesource}{author}
    \field{labeltitlesource}{title}
    \field{sortinit}{C}
    \field{sortinithash}{C}
    \field{abstract}{%
    Focussing on the prosodic labelling of Japanese as an example, the paper
  describes the application of speech synthesis technology in a variety of
  speech processing tasks. It discusses first the use of synthesised utterances
  in the forced alignment and segmentation of a speech corpus, then the use of
  generated prosodic contours to determine the prosodic phrasing of an
  utterance, and finally the comparison with speech resynthesised using the
  prosodic transcription of the original utterance in order to check the
  transcription. It closes with an analysis of results from an auto
  transcription of Japanese ToBI, and discusses some limitations of the
  proposed J-ToBI system%
    }
    \verb{doi}
    \verb 10.1109/ICSLP.1996.607292
    \endverb
    \field{isbn}{0-7803-3555-4}
    \field{pages}{2399 \bibrangedash  2402}
    \field{title}{{Autolabelling Japanese ToBI}}
    \verb{url}
    \verb http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=607292
    \endverb
    \field{volume}{4}
    \verb{file}
    \verb :Users/joshfenech/Documents/Linux Documents Backup May/Documents/Shar
    \verb ed Documents/MLDM/Project/Papers/Tobi sync TTS.pdf:pdf
    \endverb
    \field{journaltitle}{ICSLP 96. Fourth International Congress on Conference
  on Language Processing Proceedings}
    \field{year}{1996}
  \endentry

  \entry{catalunya_2017}{misc}{}
    \name{author}{1}{}{%
      {{hash=CUPd}{%
         family={Catalunya},
         familyi={C\bibinitperiod},
         given={Universitat Politècnica\bibnamedelima de},
         giveni={U\bibinitperiod\bibinitdelim P\bibinitperiod\bibinitdelim
  d\bibinitperiod},
      }}%
    }
    \strng{namehash}{CUPd1}
    \strng{fullhash}{CUPd1}
    \field{labelnamesource}{author}
    \field{labeltitlesource}{title}
    \field{sortinit}{C}
    \field{sortinithash}{C}
    \field{title}{Recurrent Neural Networks II (D2L3 Deep Learning for Speech
  and Langu...}
    \verb{url}
    \verb https://www.slideshare.net/xavigiro/recurrent-neural-networks-2-d2l3-
    \verb deep-learning-for-speech-and-language-upc-2017
    \endverb
    \field{journaltitle}{LinkedIn SlideShare}
    \field{year}{2017}
  \endentry

  \entry{practical_cryptography}{misc}{}
    \field{labeltitlesource}{title}
    \field{sortinit}{C}
    \field{sortinithash}{C}
    \field{title}{Crypto}
    \verb{url}
    \verb http://www.practicalcryptography.com/miscellaneous/machine-learning/g
    \verb uide-mel-frequency-cepstral-coefficients-mfccs/
    \endverb
    \field{journaltitle}{Practical Cryptography}
  \endentry

  \entry{dolbysubs}{misc}{}
    \field{labeltitlesource}{title}
    \field{sortinit}{D}
    \field{sortinithash}{D}
    \field{title}{Dolby CaptiView}
    \verb{url}
    \verb https://www.dolby.com/us/en/professional/cinema/products/captiview.ht
    \verb ml
    \endverb
    \field{journaltitle}{Dolby Subtitle Technologies}
  \endentry

  \entry{hoyts}{misc}{}
    \field{labeltitlesource}{title}
    \field{sortinit}{H}
    \field{sortinithash}{H}
    \field{title}{HOYTS Cinemas}
    \verb{url}
    \verb https://www.hoyts.co.nz/experiences/cc
    \endverb
    \field{journaltitle}{Hoyts}
  \endentry

  \entry{mfcc_steps}{article}{}
    \name{author}{1}{}{%
      {{hash=KDSP}{%
         family={Kumar},
         familyi={K\bibinitperiod},
         given={D.\bibnamedelima S.\bibnamedelima Pavan},
         giveni={D\bibinitperiod\bibinitdelim S\bibinitperiod\bibinitdelim
  P\bibinitperiod},
      }}%
    }
    \strng{namehash}{KDSP1}
    \strng{fullhash}{KDSP1}
    \field{labelnamesource}{author}
    \field{labeltitlesource}{title}
    \field{sortinit}{K}
    \field{sortinithash}{K}
    \verb{eprint}
    \verb 1507.04019
    \endverb
    \field{title}{Feature Normalisation for Robust Speech Recognition}
    \verb{url}
    \verb http://arxiv.org/abs/1507.04019
    \endverb
    \field{volume}{abs/1507.04019}
    \field{journaltitle}{CoRR}
    \field{eprinttype}{arXiv}
    \field{year}{2015}
  \endentry

  \entry{Ortega2009}{article}{}
    \name{author}{4}{}{%
      {{hash=OA}{%
         family={Ortega},
         familyi={O\bibinitperiod},
         given={Alfonso},
         giveni={A\bibinitperiod},
      }}%
      {{hash=GJE}{%
         family={Garcia},
         familyi={G\bibinitperiod},
         given={Jose\bibnamedelima Enrique},
         giveni={J\bibinitperiod\bibinitdelim E\bibinitperiod},
      }}%
      {{hash=MA}{%
         family={Miguel},
         familyi={M\bibinitperiod},
         given={Antonio},
         giveni={A\bibinitperiod},
      }}%
      {{hash=LE}{%
         family={Lleida},
         familyi={L\bibinitperiod},
         given={Eduardo},
         giveni={E\bibinitperiod},
      }}%
    }
    \keyw{Broadcast news,Speech recognition,Subtitling}
    \strng{namehash}{OA+1}
    \strng{fullhash}{OAGJEMALE1}
    \field{labelnamesource}{author}
    \field{labeltitlesource}{title}
    \field{sortinit}{O}
    \field{sortinithash}{O}
    \field{abstract}{%
    Subtitling of live broadcast news is a very important application to meet
  the needs of deaf and hard of hearing people. However, live subtitling is a
  high cost operation in terms of qualification human resources and therefore,
  money if high precision is desired. Automatic Speech Recognition researchers
  can help to perform this task saving both time and money developing systems
  that deliver subtitles fully synchronized with speech without human
  assistance. In this paper we present a real-time system for automatic
  subtitling of live broadcast news in Spanish based on the News Redaction
  Computer texts and an Automatic Speech Recognition engine to provide precise
  temporal alignment of speech to text scripts with negligible latency. The
  presented system is working satisfactory on the Aragonese Public Television
  from June 2008 without human assistance. Copyright {\textcopyright} 2009
  ISCA.%
    }
    \field{issn}{19909772}
    \field{pages}{2095\bibrangedash 2098}
    \field{title}{{Real-time live broadcast news subtitling system for
  Spanish}}
    \verb{url}
    \verb http://vivolab.es/demos/subtitle/subtitling.pdf
    \endverb
    \verb{file}
    \verb :Users/joshfenech/Library/Application Support/Mendeley Desktop/Downlo
    \verb aded/Ortega et al. - 2009 - Real-time live broadcast news subtitling
    \verb system for Spanish.pdf:pdf
    \endverb
    \field{journaltitle}{Proceedings of the Annual Conference of the
  International Speech Communication Association, INTERSPEECH}
    \field{year}{2009}
  \endentry

  \entry{Sabater_2017}{misc}{}
    \name{author}{1}{}{%
      {{hash=SA}{%
         family={Sabater},
         familyi={S\bibinitperiod},
         given={Alberto},
         giveni={A\bibinitperiod},
      }}%
    }
    \list{publisher}{1}{%
      {Machine Learnings}%
    }
    \strng{namehash}{SA1}
    \strng{fullhash}{SA1}
    \field{labelnamesource}{author}
    \field{labeltitlesource}{title}
    \field{sortinit}{S}
    \field{sortinithash}{S}
    \field{title}{Automatic Subtitle Synchronization – Machine Learnings}
    \verb{url}
    \verb https://machinelearnings.co/automatic-subtitle-synchronization-e188a9
    \verb 275617
    \endverb
    \field{journaltitle}{Machine Learnings}
    \field{year}{2017}
  \endentry

  \entry{Shrawankar2013}{article}{}
    \name{author}{2}{}{%
      {{hash=SU}{%
         family={Shrawankar},
         familyi={S\bibinitperiod},
         given={Urmila},
         giveni={U\bibinitperiod},
      }}%
      {{hash=TVM}{%
         family={Thakare},
         familyi={T\bibinitperiod},
         given={V\bibnamedelima M},
         giveni={V\bibinitperiod\bibinitdelim M\bibinitperiod},
      }}%
    }
    \keyw{hybrid feature extraction methods,signal processing,speech
  recognition system}
    \strng{namehash}{SUTVM1}
    \strng{fullhash}{SUTVM1}
    \field{labelnamesource}{author}
    \field{labeltitlesource}{title}
    \field{sortinit}{S}
    \field{sortinithash}{S}
    \field{abstract}{%
    The time domain waveform of a speech signal carries all of the auditory
  information. From the phonological point of view, it little can be said on
  the basis of the waveform itself. However, past research in mathematics,
  acoustics, and speech technology have provided many methods for converting
  data that can be considered as information if interpreted correctly. In order
  to find some statistically relevant information from incoming data, it is
  important to have mechanisms for reducing the information of each segment in
  the audio signal into a relatively small number of parameters, or features.
  These features should describe each segment in such a characteristic way that
  other similar segments can be grouped together by comparing their features.
  There are enormous interesting and exceptional ways to describe the speech
  signal in terms of parameters. Though, they all have their strengths and
  weaknesses, we have presented some of the most used methods with their
  importance.%
    }
    \verb{eprint}
    \verb 1305.1145
    \endverb
    \field{pages}{412\bibrangedash 418}
    \field{title}{{Techniques for Feature Extraction In Speech Recognition
  System : A Comparative Study}}
    \verb{url}
    \verb http://arxiv.org/abs/1305.1145
    \endverb
    \verb{file}
    \verb :Users/joshfenech/Library/Application Support/Mendeley Desktop/Downlo
    \verb aded/Shrawankar, Thakare - 2013 - Techniques for Feature Extraction I
    \verb n Speech Recognition System A Comparative Study.pdf:pdf
    \endverb
    \field{journaltitle}{International Journal Of Computer Applications In
  Engineering, Technology and Sciences (IJCAETS),ISSN 0974-3596}
    \field{annotation}{%
    Not sure if published in 2010 or 2013.%
    }
    \field{eprinttype}{arXiv}
    \field{year}{2013}
  \endentry

  \entry{subtitledshows}{misc}{}
    \list{publisher}{1}{%
      {YourLocalCinema}%
    }
    \field{labeltitlesource}{title}
    \field{sortinit}{S}
    \field{sortinithash}{S}
    \field{title}{Subtitled Cinema Showings in London}
    \verb{url}
    \verb http://yourlocalcinema.com/london.central.html
    \endverb
    \field{journaltitle}{Subtitled Shows}
  \endentry

  \entry{Tucci2010}{article}{}
    \name{author}{3}{}{%
      {{hash=TDL}{%
         family={Tucci},
         familyi={T\bibinitperiod},
         given={Debara\bibnamedelima L.},
         giveni={D\bibinitperiod\bibinitdelim L\bibinitperiod},
      }}%
      {{hash=MMH}{%
         family={Merson},
         familyi={M\bibinitperiod},
         given={Michael\bibnamedelima H.},
         giveni={M\bibinitperiod\bibinitdelim H\bibinitperiod},
      }}%
      {{hash=WBS}{%
         family={Wilson},
         familyi={W\bibinitperiod},
         given={Blake\bibnamedelima S.},
         giveni={B\bibinitperiod\bibinitdelim S\bibinitperiod},
      }}%
    }
    \keyw{Deafness,Global health hearing,Hearing impairment,Hearing loss}
    \strng{namehash}{TDLMMHWBS1}
    \strng{fullhash}{TDLMMHWBS1}
    \field{labelnamesource}{author}
    \field{labeltitlesource}{title}
    \field{sortinit}{T}
    \field{sortinithash}{T}
    \field{abstract}{%
    Background: Hearing loss (HL) and deafness are global issues that affect at
  least 278 million people worldwide. Two thirds of the people who have HL
  worldwide live in developing countries. Importantly, it is estimated that
  50{\%} of this HL can be prevented. In developing countries, funding for
  prevention, early detection, and rehabilitative programs is severely limited,
  and therefore, agencies must compete against priorities to treat
  life-threatening, pandemic diseases such as human immunodeficiency virus,
  malaria, and tuberculosis. Delays in diagnosis are common, and social
  attitudes, local customs, and cultural bias are contributing factors.
  Objective: The purpose of this review is to gain an understanding of the
  prevalence of HL in the developing world and to focus attention on the
  growing need for both prevention and effective treatment programs. A second
  goal is to use this information to suggest priorities and approaches to
  address these problems worldwide. Data Sources: The data were compiled from a
  review of the literature on the global impacts of hearing impairment and
  recently published reports on the prevalence and cause of hearing impairment
  in developing nations. Conclusion:: The high prevalence of HL in the
  developing world is due to a variety of factors, including lack of widespread
  comprehensive immunization programs and other medical care, and inadequate
  funds for intervention once HL is identified. International organizations,
  governments, and nongovernment organizations have many opportunities to
  prevent and treat HL through cost-effective means. {\textcopyright} 2009,
  Otology {\&} Neurotology, Inc.%
    }
    \verb{doi}
    \verb 10.1097/MAO.0b013e3181c0eaec
    \endverb
    \field{isbn}{15317129 (ISSN)}
    \field{issn}{15317129}
    \field{title}{{A summary of the literature on global hearing impairment:
  Current status and priorities for action}}
    \field{journaltitle}{Otology and Neurotology}
    \field{year}{2010}
  \endentry
\enddatalist
\endinput
